#! /usr/bin/env Rscript
dir <- getwd()
if (!is.null(dir)) {
	setwd(dir)
}


args <- commandArgs(trailing = TRUE)
number <- args[1]
filename_save <-args[2]


source('pcalg.R')
source('AllClasses.R')
source('Aaux.R')
source('I_FCI_mod1.R')
library(graph) 

# for python-style list comprehension
library(comprehenr)

# input synthetic data generated by GenerateInterventionalData.ipynb
df_list <- list()
for (i in 1:number) {
	df_list[[i]]<-read.csv(args[i+2],header = TRUE)
}


if (any(names(df_list[[1]])!=names(df_list[[1]]))) {
  stop("Input datasets columns not ordered!")
}

# Remove the latent confounders, L1 and L2
drops <- c("L1","L2")

# df1 <- subset(df1,select = -c("L1","L2"))
# df2 <- subset(df2,select = -c("L1","L2"))
env_list=list()
for (i in 1:number) {
	df_list[[i]]<-  df_list[[i]][ , !(names(df_list[[i]]) %in% drops)]
	env_list[[i]]=matrix(i,nrow=nrow(df_list[[i]]),ncol=1)
}


# Concatenate the datasets and create a dataset index vector
df=do.call(rbind,df_list)
env_index=do.call(rbind,env_list)

envs <- unique(env_index)
no_of_environments <- length(envs)
print(envs)

# Create F-nodes. 
# We will be using only pairs of datasets for every F-node
# This will allow us to use the conditional independence tester to check invaraince across interventional distributions
# since F node will be labeled 0 for env. 1 and 1 for env. 2. Then we simply check if 
# F cond. indep. from Y given W for checking (F_||_Y|W) separation statement.
# In accordance with the paper, if indep., all other F nodes will be added manually to the sep. set W

# Use tuples as subscripts to F node names:
F_envs <- to_list(for(i in 1:no_of_environments) for(j in i+1:no_of_environments) if(!is.na(envs[j])) c(envs[i],envs[j]))
# NA check required since even if i+1 is larger than no_of_env. comprehension assigns it unlike python
F_node_names <- to_list(for (i in F_envs) paste("F_",paste(i[[1]],i[[2]],sep=''),sep=''))
no_of_F_nodes <- length(F_node_names)
# Augment the data with F nodes and the corresponding values. Use values 0,1 for the relevant datasets and -1 for the irrelevant datasets
F_vals <- matrix(-1L,nrow=nrow(df),ncol=length(F_node_names))

for (i in 1:no_of_F_nodes){
  F_vals[env_index==F_envs[[i]][1],i]=0 # rows from the first environment assigned 0
  F_vals[env_index==F_envs[[i]][2],i]=1 # rows from the second environment assigned 1
}
colnames(F_vals)<-F_node_names
# col. number in updated data: ncol(gmInt)+

df <- cbind(df,F_vals)

# Now we are ready to pass data onto I_fci function with new variable names and F_node_names
# Assuming discrete data
suffStat <- list(dm = df, adaptDF=FALSE)
res <- I_fci(suffStat, indepTest=disCItest, skel.method='stable', labels = colnames(df),
           alpha = 0.05, doPdsep = FALSE, F_node_names = F_node_names,verbose=TRUE)



write.csv(res@amat,file=filename_save)

